{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!activate base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from paddleocr import PaddleOCR,draw_ocr\n",
    "    import PIL\n",
    "    from PIL import ImageFont\n",
    "    from PIL import Image\n",
    "    from PIL import ImageTk\n",
    "    import PIL.Image\n",
    "    from imutils import paths\n",
    "    import cv2\n",
    "    from matplotlib import pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import os\n",
    "    import shutil\n",
    "    import pandas as pd\n",
    "    from pylab import imshow\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import seaborn as sns\n",
    "    import albumentations as albu\n",
    "    from albumentations.pytorch.transforms import ToTensorV2\n",
    "    from iglovikov_helper_functions.dl.pytorch.utils import tensor_from_rgb_image\n",
    "    from iglovikov_helper_functions.utils.image_utils import load_rgb\n",
    "    from datasouls_antispoof.pre_trained_models import create_model\n",
    "    from datasouls_antispoof.class_mapping import class_mapping\n",
    "    from imutils.video import VideoStream\n",
    "    import tensorflow as tf\n",
    "    import argparse\n",
    "    import imutils\n",
    "    import pickle\n",
    "    import time \n",
    "    import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)    \n",
    "    height, width  = im_data.shape[:2]\n",
    "    \n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)    \n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])    \n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')    \n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def paddle_man(img_path):\n",
    "    ocr = PaddleOCR(det_model_dir='paddleOCR_V2_EN_GEN_SRV_MOB_T/ch_PP-OCRv2_det_distill_train', rec_model_dir='paddleOCR_V2_EN_GEN_SRV_MOB_T/ret_model/ch_PP-OCRv2_rec_train',cls_model_dir='paddleOCR_V2_EN_GEN_SRV_MOB_T/cls_model/ch_ppocr_mobile_v2.0_cls_train',use_angle_cls=True) ;\n",
    "    result = ocr.ocr(img_path,cls=True);\n",
    "    txts = [line[1][0] for line in result]\n",
    "    scores = [line[1][1] for line in result]\n",
    "    \n",
    "    # draw result\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    boxes = [line[0] for line in result]\n",
    "    txts = [line[1][0] for line in result]\n",
    "    scores = [line[1][1] for line in result]\n",
    "    font = ImageFont.load_default()\n",
    "    \n",
    "    im_show = draw_ocr(image, boxes, txts, scores, font_path='L:/CV/PaddleOCR/PaddleOCR/doc/fonts/simfang.ttf')\n",
    "    im_show = Image.fromarray(im_show)\n",
    "    im_show.save('result.jpg')\n",
    "    im = Image.open(\"result.jpg\")\n",
    "    im.show() \n",
    "    return txts,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/28816046/\n",
    "#displaying-different-images-with-actual-size-in-matplotlib-subplot\n",
    "%matplotlib inline\n",
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)    \n",
    "    height, width  = im_data.shape[:2]\n",
    "    \n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)    \n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])    \n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')    \n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_code(img):\n",
    "    #Remove previous results\n",
    "    isdir = os.path.isdir('runs/detect')\n",
    "    if isdir == True:\n",
    "        shutil.rmtree(r'runs/detect')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #Convert image to gray scale\n",
    "    \n",
    "    read_img = cv2.imread(img)\n",
    "    gray_image=cv2.cvtColor(read_img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite('temp/gray_image.jpg', gray_image)\n",
    "    \n",
    "    #Detect VIN Region\n",
    "    !python yolov5/detect.py --weights yolov5/yolov5/weights/large/best.pt --img 416 --conf 0.6 --source temp/gray_image.jpg --project runs/detect/ --name exp --save-crop\n",
    "    #import torch\n",
    "    #model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/yolov5/weights/best.pt')  # default\n",
    "    #imgs = ['temp/gray_image.jpg'] \n",
    "    #results = model(imgs)\n",
    "    #results.xyxy[0]  \n",
    "    #results.pandas().xyxy[0]  \n",
    "    #crops = results.crop(save=True)\n",
    "    \n",
    "    \n",
    "    ##Check if directry present(True if object detection is correct)\n",
    "    detect_folder='runs/detect/exp/crops/Letters/'\n",
    "    isdir = os.path.isdir(detect_folder)\n",
    "    if isdir == False:\n",
    "        txts,score=paddle_man(img)   \n",
    "    else:\n",
    "        print('Dir exist')\n",
    "        file = os.listdir(detect_folder)\n",
    "        file=file[0]\n",
    "        path = (detect_folder+\"\"+file)\n",
    "        src = cv2.imread(path)\n",
    "        image = cv2.rotate(src, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cv2.imwrite(\"runs/temp/\"+file, image)    \n",
    "        #Convert to inverted imge\n",
    "        gray_image_file='runs/temp/'+ file\n",
    "        image_read=cv2.imread(gray_image_file)\n",
    "        inverted_image = cv2.bitwise_not(image_read)\n",
    "        cv2.imwrite(\"runs/temp/inverted.jpg\", inverted_image)\n",
    "        #Pass images to OCR\n",
    "        txts,score=paddle_man(\"runs/temp/inverted.jpg\")\n",
    "        \n",
    "    #torch.cuda.empty_cache()\n",
    "    \n",
    "    return txts,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liveness_det_one(img_in):\n",
    "    ##Livesness detection\n",
    "    ##Datasouls\n",
    "    ###   \n",
    "    #model = create_model(\"tf_efficientnet_b3_ns\")\n",
    "    model1 = create_model(\"tf_efficientnet_b3_ns\")\n",
    "    model2 = create_model(\"swsl_resnext50_32x4d\")\n",
    "    model1.eval();\n",
    "    model2.eval();\n",
    "    image_replay = load_rgb(img)\n",
    "    #imshow(image_replay)\n",
    "    ###\n",
    "    transform = albu.Compose([albu.PadIfNeeded(min_height=400, min_width=400),\n",
    "                              albu.CenterCrop(height=400, width=400), \n",
    "                              albu.Normalize(p=1), \n",
    "                              albu.pytorch.ToTensorV2(p=1)], p=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction1 = model1(torch.unsqueeze(transform(image=image_replay)['image'], 0)).numpy()[0]\n",
    "        prediction2 = model2(torch.unsqueeze(transform(image=image_replay)['image'], 0)).numpy()[0]\n",
    "\n",
    "    df1 = pd.DataFrame({\"prediction\": prediction1, \"class_name\": class_mapping.keys()})\n",
    "    df2 = pd.DataFrame({\"prediction\": prediction2, \"class_name\": class_mapping.keys()})\n",
    "    #sns.barplot(data=df1, x=\"prediction\", y=\"class_name\") \n",
    "    #sns.barplot(data=df2, x=\"prediction\", y=\"class_name\") \n",
    "    \n",
    "    res1_df=df1.loc[df1['prediction'].idxmax()]\n",
    "    res2_df=df2.loc[df2['prediction'].idxmax()]\n",
    "    redf1,redf2,pred1,pred2=res1_df.class_name,res2_df.class_name,res1_df.prediction,res2_df.prediction\n",
    "    ###\n",
    "    return redf1,redf2,pred1,pred2\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##Livesness detection\n",
    "    ##Neural Network(Binary classification)\n",
    "\n",
    "def liveness_det_two(img):\n",
    "    liveness_model = tf.keras.models.load_model('LIVENESS_DETECT/face_liveness_detection/model',custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "    le = pickle.loads(open('LIVENESS_DETECT/face_liveness_detection/label_encoder','rb').read())\n",
    "    \n",
    "    ##Read image and resize --\n",
    "    frame = cv2.imread(img)\n",
    "    face = cv2.resize(frame, (224,224))\n",
    "    \n",
    "    face = face.astype('float') / 255.0 \n",
    "    face = tf.keras.preprocessing.image.img_to_array(face)\n",
    "    # tf model require batch of data to feed in\n",
    "    # so if we need only one image at a time, we have to add one more dimension\n",
    "    # in this case it's the same with [face]\n",
    "    face = np.expand_dims(face, axis=0)\n",
    "    \n",
    "    preds = liveness_model.predict(face)[0]\n",
    "    j = np.argmax(preds)\n",
    "    label = le.classes_[j]\n",
    "    result2= 'fake' if label ==1 else 'real'\n",
    "    res3df=pd.DataFrame(preds,columns=['dd'])\n",
    "    tmp_df=res3df.loc[res3df['dd'].idxmax()]\n",
    "    pred3=tmp_df.dd\n",
    "    return result2,pred3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir exist\n",
      "[2022/03/03 23:00:26] root WARNING: version PP-OCRv2 not support cls models, auto switch to version PP-OCR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5/yolov5/weights/large/best.pt'], source=temp/gray_image.jpg, imgsz=[416, 416], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect/, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  v6.0-131-gc77a5a8 torch 1.10.2+cu113 CUDA:0 (GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 367 layers, 46108278 parameters, 0 gradients, 107.8 GFLOPs\n",
      "image 1/1 L:\\CV\\MAIN_PRO_POC\\temp\\gray_image.jpg: 416x256 1 Letters, Done. (0.020s)\n",
      "Speed: 1.0ms pre-process, 20.0ms inference, 4.4ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\exp\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(benchmark=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='paddleOCR_V2_EN_GEN_SRV_MOB_T/cls_model/ch_ppocr_mobile_v2.0_cls_train', cls_thresh=0.9, cpu_threads=10, det=True, det_algorithm='DB', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='paddleOCR_V2_EN_GEN_SRV_MOB_T/ch_PP-OCRv2_det_distill_train', det_pse_box_thresh=0.85, det_pse_box_type='box', det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_polygon=False, det_sast_score_thresh=0.5, drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_polygon=True, e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, gpu_mem=500, help='==SUPPRESS==', image_dir=None, ir_optim=True, label_list=['0', '180'], lang='ch', layout_path_model='lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config', max_batch_size=10, max_text_length=25, min_subgraph_size=15, ocr_version='PP-OCRv2', output='./output/table', precision='fp32', process_id=0, rec=True, rec_algorithm='CRNN', rec_batch_num=6, rec_char_dict_path='L:\\\\ANACONDA\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', rec_image_shape='3, 32, 320', rec_model_dir='paddleOCR_V2_EN_GEN_SRV_MOB_T/ret_model/ch_PP-OCRv2_rec_train', save_log_path='./log_output/', show_log=True, structure_version='STRUCTURE', table_char_dict_path=None, table_char_type='en', table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mp=False, use_onnx=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=True)\n",
      "[2022/03/03 23:00:26] root DEBUG: dt_boxes num : 1, elapse : 0.04600954055786133\n",
      "[2022/03/03 23:00:26] root DEBUG: cls num  : 1, elapse : 0.012002944946289062\n",
      "[2022/03/03 23:00:26] root DEBUG: rec_res num  : 1, elapse : 0.07501673698425293\n",
      "\n",
      "\n",
      "Recognised Text : ['MBL JAW185MCG03051']\n",
      "Accuracy : [0.84506947]\n",
      "\n",
      "Fake image detection result: real  --> Accuracy: 0.999972\n"
     ]
    }
   ],
   "source": [
    "##Testing##\n",
    "torch.cuda.empty_cache()\n",
    "#folder='test/HERO_PRINTED/replay/'       ##Images captired from computer screen\n",
    "#folder='test/HERO_PRINTED/bw_p/'         ##Images captured from printed paper (B/W)\n",
    "#folder='test/HERO_PRINTED/color_p/'      ##Images captured from color printed paper\n",
    "folder='test/HERO_PRINTED/real/'          ##Real captured images\n",
    "\n",
    "file='real10.jpeg'\n",
    "\n",
    "\n",
    "img=(folder+\"\"+file)\n",
    "liv3,pred3=liveness_det_two(img);\n",
    "##Model3\n",
    "if liv3 == 'fake':\n",
    "    print(\"Spoof detection result:\",liv3,\" --> Accuracy:\",pred3)\n",
    "    #!python pp.py\n",
    "else:\n",
    "#display(img)\n",
    "    txts,score=main_code(img);\n",
    "    #redf1,redf2,pred1,pred2=liveness_det_one(img);\n",
    "    #liv3,pred3=liveness_det_two(img);\n",
    "\n",
    "\n",
    "    ###Printing Results\n",
    "    print(\"\\n\")\n",
    "    print(\"Recognised Text :\",txts)\n",
    "    print(\"Accuracy :\",score)\n",
    "    print()\n",
    "    ###Liveness Detection Results###\n",
    "    ##Model1 & Model2\n",
    "    #print(\"Image Liveness Detection Result:\\n\")\n",
    "    #print(\"Model1 :\",redf1,\" --> Accuracy:\",pred1)\n",
    "    #print(\"Model2 :\",redf2,\" --> Accuracy:\",pred2)\n",
    "    print(\"Fake image detection result:\",liv3,\" --> Accuracy:\",pred3)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spoof detection result: fake  --> Accuracy: 0.99850625\n"
     ]
    }
   ],
   "source": [
    "####OPENCV\n",
    "\n",
    "\n",
    "import cv2 \n",
    "\n",
    "key = cv2. waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    try:\n",
    "        check, frame = webcam.read()\n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'): \n",
    "            cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "            webcam.release()\n",
    "            img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "            img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "            cv2.waitKey(1650)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            img_ = cv2.imread('saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "        \n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            print(\"Turning off camera.\")\n",
    "            webcam.release()\n",
    "            print(\"Camera off.\")\n",
    "            print(\"Program ended.\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "    except(KeyboardInterrupt):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "\n",
    "img=('saved_img.jpg')\n",
    "liv3,pred3=liveness_det_two(img);\n",
    "##Model3\n",
    "if liv3 == 'fake':\n",
    "    print(\"Spoof detection result:\",liv3,\" --> Accuracy:\",pred3)\n",
    "else:\n",
    "#display(img)\n",
    "    txts,score=main_code(img);\n",
    "    #redf1,redf2,pred1,pred2=liveness_det_one(img);\n",
    "    #liv3,pred3=liveness_det_two(img);\n",
    "\n",
    "\n",
    "    ###Printing Results\n",
    "    print(\"\\n\")\n",
    "    print(\"Recognised Text :\",txts)\n",
    "    print(\"Accuracy :\",score)\n",
    "    print()\n",
    "    ###Liveness Detection Results###\n",
    "    ##Model1 & Model2\n",
    "    #print(\"Image Liveness Detection Result:\\n\")\n",
    "    #print(\"Model1 :\",redf1,\" --> Accuracy:\",pred1)\n",
    "    #print(\"Model2 :\",redf2,\" --> Accuracy:\",pred2)\n",
    "    print(\"Fake image detection result:\",liv3,\" --> Accuracy:\",pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('result - Copy.jpg',cv2.IMREAD_UNCHANGED)\n",
    "position = (10,50)\n",
    "cv2.putText(image,\"Python Examples\",position,cv2.FONT_HERSHEY_SIMPLEX,1,(0, 255, 0),3) \n",
    "cv2.imwrite('result - Copy.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################TKINTER\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def fh():\n",
    "    img=('cap_img.jpg')\n",
    "    fake_res='this is a fake image'\n",
    "    real_res='this is a real image'\n",
    "    \n",
    "    \n",
    "    liv3,pred3=liveness_det_two(img);\n",
    "    ##Model3\n",
    "    if liv3 == 'fake':\n",
    "        print(\"Spoof detection result:\",liv3,\" --> Accuracy:\",pred3)\n",
    "    \n",
    "        image = cv2.imread(img,cv2.IMREAD_UNCHANGED)\n",
    "        position = (10,50)\n",
    "        cv2.putText(image,\"this is a fake image\",position,cv2.FONT_HERSHEY_SIMPLEX,1,(0, 0, 255),3) \n",
    "        cv2.imwrite(img, image)\n",
    "        !python pp.py\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        txts,score=main_code(img);\n",
    "    \n",
    "        print(\"Spoof detection result:\",liv3,\" --> Accuracy:\",pred3)\n",
    "        image = cv2.imread(img,cv2.IMREAD_UNCHANGED)\n",
    "        position = (10,50)\n",
    "        cv2.putText(image,\"this is a real image\",position,cv2.FONT_HERSHEY_SIMPLEX,1,(0, 255, 0),3) \n",
    "        cv2.imwrite(img, image)\n",
    "        !python pp.py\n",
    "    \n",
    "    \n",
    "        ###Printing OCR Results\n",
    "        print(\"\\n\")\n",
    "        print(\"Recognised Text :\",txts)\n",
    "        print(\"Accuracy :\",score)\n",
    "        print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"L:\\ANACONDA\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\rajes\\AppData\\Local\\Temp/ipykernel_8620/707825685.py\", line 59, in snapshot\n",
      "    fh()\n",
      "  File \"C:\\Users\\rajes\\AppData\\Local\\Temp/ipykernel_8620/4077823848.py\", line 11, in fh\n",
      "    liv3,pred3=liveness_det_two(img);\n",
      "  File \"C:\\Users\\rajes\\AppData\\Local\\Temp/ipykernel_8620/224066039.py\", line 43, in liveness_det_two\n",
      "    frame = cv2.imread(img)\n",
      "NameError: name 'img' is not defined\n"
     ]
    }
   ],
   "source": [
    "################TKINTER\n",
    "\n",
    "\n",
    "import tkinter as tk\n",
    "import cv2\n",
    "import time\n",
    "import datetime as dt\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tkinter import *  \n",
    "\n",
    "\n",
    "class App:\n",
    "    def __init__(self, window, window_title, video_source=0):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.video_source = video_source\n",
    "        self.ok=False\n",
    "\n",
    "        #timer\n",
    "        self.timer=ElapsedTimeClock(self.window)\n",
    "\n",
    "        # open video source (by default this will try to open the computer webcam)\n",
    "        self.vid = VideoCapture(self.video_source)\n",
    "\n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas = tk.Canvas(window, width = self.vid.width, height = self.vid.height)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # Button that lets the user take a snapshot\n",
    "        self.btn_snapshot=tk.Button(window, text=\"Snapshot\", command=self.snapshot)\n",
    "        self.btn_snapshot.pack(side=tk.LEFT)\n",
    "\n",
    "        #video control buttons\n",
    "\n",
    "        self.btn_start=tk.Button(window, text='START', command=self.open_camera)\n",
    "        self.btn_start.pack(side=tk.LEFT)\n",
    "\n",
    "        self.btn_stop=tk.Button(window, text='STOP', command=self.close_camera)\n",
    "        self.btn_stop.pack(side=tk.LEFT)\n",
    "\n",
    "        # quit button\n",
    "        self.btn_quit=tk.Button(window, text='QUIT', command=window.destroy)\n",
    "        self.btn_quit.pack(side=tk.LEFT)\n",
    "\n",
    "        # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay=10\n",
    "        self.update()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def snapshot(self):\n",
    "        # Get a frame from the video source\n",
    "        ret,frame=self.vid.get_frame()\n",
    "\n",
    "        if ret:\n",
    "            cv2.imwrite(\"cap_img\"+\".jpg\",cv2.cvtColor(frame,cv2.COLOR_RGB2BGR))\n",
    "            fh()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def open_camera(self):\n",
    "        self.ok = True\n",
    "        self.timer.start()\n",
    "        print(\"camera opened => Recording\")\n",
    "\n",
    "\n",
    "\n",
    "    def close_camera(self):\n",
    "        self.ok = False\n",
    "        self.timer.stop()\n",
    "        print(\"camera closed => Not Recording\")\n",
    "\n",
    "       \n",
    "    def update(self):\n",
    "\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        if self.ok:\n",
    "            self.vid.out.write(cv2.cvtColor(frame,cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        if ret:\n",
    "            self.photo = ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, image = self.photo, anchor = tk.NW)\n",
    "        self.window.after(self.delay,self.update)\n",
    "\n",
    "\n",
    "class VideoCapture:\n",
    "    def __init__(self, video_source=0):\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        # Command Line Parser\n",
    "        #args=CommandLineParser().args\n",
    "\n",
    "        \n",
    "        #create videowriter\n",
    "\n",
    "        # 1. Video Type\n",
    "        VIDEO_TYPE = {\n",
    "            'avi': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "            #'mp4': cv2.VideoWriter_fourcc(*'H264'),\n",
    "            'mp4': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "        }\n",
    "\n",
    "        self.fourcc=VIDEO_TYPE['mp4']\n",
    "\n",
    "        # 2. Video Dimension\n",
    "        STD_DIMENSIONS =  {\n",
    "            '480p': (640, 480),\n",
    "            '720p': (1280, 720),\n",
    "            '1080p': (1920, 1080),\n",
    "            '4k': (3840, 2160),\n",
    "        }\n",
    "        res=STD_DIMENSIONS['480p']\n",
    "        #print(args.name,self.fourcc,res)\n",
    "        self.out = cv2.VideoWriter('output'+'.'+'output',self.fourcc,10,res)\n",
    "\n",
    "        #set video sourec width and height\n",
    "        self.vid.set(3,res[0])\n",
    "        self.vid.set(4,res[1])\n",
    "\n",
    "        # Get video source width and height\n",
    "        self.width,self.height=res\n",
    "\n",
    "\n",
    "    # To get frames\n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return (ret, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (ret, None)\n",
    "\n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "            self.out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "class ElapsedTimeClock:\n",
    "    def __init__(self,window):\n",
    "        self.T=tk.Label(window,text='00:00:00',font=('times', 20, 'bold'), bg='green')\n",
    "        self.T.pack(fill=tk.BOTH, expand=1)\n",
    "        self.elapsedTime=dt.datetime(1,1,1)\n",
    "        self.running=0\n",
    "        self.lastTime=''\n",
    "        t = time.localtime()\n",
    "        self.zeroTime = dt.timedelta(hours=t[3], minutes=t[4], seconds=t[5])\n",
    "        # self.tick()\n",
    "\n",
    " \n",
    "    def tick(self):\n",
    "        # get the current local time from the PC\n",
    "        self.now = dt.datetime(1, 1, 1).now()\n",
    "        self.elapsedTime = self.now - self.zeroTime\n",
    "        self.time2 = self.elapsedTime.strftime('%H:%M:%S')\n",
    "        # if time string has changed, update it\n",
    "        if self.time2 != self.lastTime:\n",
    "            self.lastTime = self.time2\n",
    "            self.T.config(text=self.time2)\n",
    "        # calls itself every 200 milliseconds\n",
    "        # to update the time display as needed\n",
    "        # could use >200 ms, but display gets jerky\n",
    "        self.updwin=self.T.after(100, self.tick)\n",
    "\n",
    "\n",
    "    def start(self):\n",
    "            if not self.running:\n",
    "                self.zeroTime=dt.datetime(1, 1, 1).now()-self.elapsedTime\n",
    "                self.tick()\n",
    "                self.running=1\n",
    "\n",
    "    def stop(self):\n",
    "            if self.running:\n",
    "                self.T.after_cancel(self.updwin)\n",
    "                self.elapsedTime=dt.datetime(1, 1, 1).now()-self.zeroTime\n",
    "                self.time2=self.elapsedTime\n",
    "                self.running=0\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create a window and pass it to the Application object\n",
    "    App(tk.Tk(),'Video Recorder')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Liveness DetectOOnly###\n",
    "##Liveness DetectOOnly###\n",
    "\n",
    "#Variables\n",
    "result=[]\n",
    "img=[]\n",
    "imagePaths=[]\n",
    "accuracy=[]\n",
    "imagePaths = sorted(list(paths.list_images('test/HERO_PRINTED/replay/')))\n",
    "for img in imagePaths:\n",
    "\n",
    "    liv3,pred3=liveness_det_two(img);\n",
    "    result.append(liv3)\n",
    "    accuracy.append(pred3)\n",
    "\n",
    "    ##Model3\n",
    "#print(\"result of all images:\",result)\n",
    "#print(\"image count:\",len(result))\n",
    "data=pd.DataFrame(result,accuracy)\n",
    "data.to_csv('replay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0b0e9607aa7199b1ab863cb1f0d61516a11e022c153f178d70caf221baabe17"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
